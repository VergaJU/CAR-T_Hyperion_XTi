{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092b0164-5945-481b-8596-4e8425681171",
   "metadata": {},
   "source": [
    "# Create single 'pixel' object\n",
    "\n",
    "- Jacopo Umberto Verga\n",
    "- 08/13/2024\n",
    "\n",
    "\n",
    "After pre-processing the images\n",
    "- [steinbock](https://bodenmillergroup.github.io/steinbock/latest/) extract tiff files\n",
    "- Extract single channel files with [imagej](https://imagej.net/ij/) and python\n",
    "- Registering each slide with [skimage](https://scikit-image.org/)\n",
    "\n",
    "We need to import the pixels values as a \"single cell object\". The AnnData format allows us to easily handle the pixels and perform spatial analysis as for the 2D data.\n",
    "\n",
    "\n",
    "Steps:\n",
    "- Import each pixels as an observation of the AnnData object\n",
    "    - Channels values as expression, coordinates in the metadata\n",
    "- Remove zero value pixels (padding)\n",
    "- Remove non-tissue pixels using watershed segmentation\n",
    "    - clustering of the pixels with non-tissue pixels increase the noise and masks real biological signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ac92d9-0969-410a-aea9-b504ecf16433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import scanpy as sc\n",
    "from IPython.display import Markdown\n",
    "from clustering_Modules.utils import image_preprocessing_parallel_dev  as img_pre\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ac6109-34e6-4a65-be04-7196ccf80fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_path='./samples/single_channel_images/D0246_registered/D02461_section02_001/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa64052-b0c5-4739-96d3-56a2a72bd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all channels\n",
    "channels=natsorted([('_'.join(string.split('.')[0].split('_')[1:])\n",
    "                     .replace('_(c-kit)','')\n",
    "                     .replace('CD73_','')\n",
    "                     .replace('CD44_','')\n",
    "                     .replace('TIGIT_','TIGIT')) for string in os.listdir(slide_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f7123d-a48b-44ba-a43b-7201faa83fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_channels(image_path, channels):\n",
    "    channel_data = {}\n",
    "    for channel in channels:\n",
    "        channel_file=[f for f in os.listdir(slide_path) if channel in f][0]\n",
    "        channel_filename = os.path.join(image_path, f\"{channel_file}\")\n",
    "        # read channel file\n",
    "        channel_data[channel] = tiff.imread(channel_filename)\n",
    "    return channel_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318af7e1-c1d5-465f-aeef-62c4399b2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_anndata(image_name, channel_data,slide):\n",
    "    # Extract the dimensions from one of the channels\n",
    "    example_channel = list(channel_data.values())[0]\n",
    "    height, width = example_channel.shape\n",
    "    library_id=image_name + '_' + str(slide)\n",
    "    # Create a DataFrame for the expression matrix (adata.X)\n",
    "    expression_matrix = np.zeros((height * width, len(channel_data)))\n",
    "    # Get expression of each channel as flat array\n",
    "    for i, (channel, data) in enumerate(channel_data.items()):\n",
    "        expression_matrix[:, i] = data.flatten()\n",
    "\n",
    "    img_list = list(channel_data.values())\n",
    "    img_array = np.stack(img_list, axis=-1)\n",
    "\n",
    "    # Create the metadata DataFrame (adata.obs)\n",
    "    x_coords, y_coords = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    obs = pd.DataFrame({\n",
    "        'x': x_coords.flatten(),\n",
    "        'y': y_coords.flatten(),\n",
    "        'width_px':width, \n",
    "        'height_px':height, \n",
    "        'z': slide,\n",
    "        'image': image_name,\n",
    "        'library_id':library_id\n",
    "    })\n",
    "    # Create spatial dictionary\n",
    "    uns = {\n",
    "        library_id:{\n",
    "            'images':{\n",
    "                'hires':img_array\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create the AnnData object\n",
    "    adata = ad.AnnData(X=expression_matrix, obs=obs, var=pd.DataFrame(index=channel_data.keys()))\n",
    "    adata.obs_names = adata.obs['x'].astype(str)+'_'+adata.obs['y'].astype(str)+'_'+adata.obs['z'].astype(str)+'_'+image_name\n",
    "    return adata, uns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfad7e7-91a6-4cb3-ad0d-00f4c0a6b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slides_path='./samples/single_channel_images/'\n",
    "images_ids=['D0246','G4090','K0401']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ae578e-6ca6-459d-b799-d1028af76e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name=images_ids[0]\n",
    "def process_sections(all_slides_path, image_name,channels):\n",
    "    # process all sections of one sample\n",
    "    image_path=os.path.join(all_slides_path, image_name+'_registered')\n",
    "    sections=natsorted(os.listdir(image_path))\n",
    "    adatas=[]\n",
    "    unses={}\n",
    "    for i,section in enumerate(sections):\n",
    "        slide_path=os.path.join(image_path,section)\n",
    "        channel_data=load_image_channels(slide_path, channels)\n",
    "        adata,uns=create_anndata(image_name, channel_data,i+1)\n",
    "        adatas.append(adata)\n",
    "        unses[list(uns.keys())[0]]=list(uns.values())[0]\n",
    "    return adatas,unses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4bc3643-5d38-4d37-aba1-d0f0ec21082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas=[]\n",
    "unses={}\n",
    "for image_name in images_ids:\n",
    "    # process all images\n",
    "    adata,uns=process_sections(all_slides_path, image_name,channels)\n",
    "    adatas.extend(adata)\n",
    "    unses.update(uns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65479fef-410e-4a5b-8998-8a6ab542041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat adatas of each image\n",
    "adatas=ad.concat(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6d9c0e-9e38-4a0d-815d-fd4e6123bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .uns['spatial']\n",
    "adatas.uns['spatial']=unses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d84d1a7-eb91-4896-a77d-61b66c70f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del unses since takes a lot of space\n",
    "del unses\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1842201-87e5-4add-aaf4-13c51fbc1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pixels with zero values for all the markers (padding pixels)\n",
    "sc.pp.filter_cells(adatas,min_genes=1)\n",
    "adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6951e4f3-d55e-4d96-ac85-715d7744e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalized expression layer, change normalization to 99.9 quantile since some markers are really lowly expressed in some slides\n",
    "adatas.layers['exprs'] = img_pre.normalize_channels_mat(\n",
    "    img_pre.normalize_channels_mat(\n",
    "        adatas.X, method='arcsinh', cofactor=None\n",
    "    ),\n",
    "    method='quantile', quantile=.999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9436abb7-356c-476f-b0a3-3cd58d1a6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75bdf642-9e76-485a-9037-b55c8b4dedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dirty dataset\n",
    "adatas.write('./samples/adata_dirty.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36459402-e4c1-427f-bdbf-096a8cde9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adatas\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56309d99-0a84-441a-bb8e-3e7aa5976a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas=sc.read('./samples/adata_dirty.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86a14-807f-4a4b-b16b-2992cabb16bf",
   "metadata": {},
   "source": [
    "## Watershed Segmentation:\n",
    "\n",
    "To select the pixels falling in the tissue I am going to use the function already wrote in adipo_finder, steps for each slide:\n",
    "- Normalize and sum values from all the channels\n",
    "- Apply gaussian blur to get smoother borders and reduce noise\n",
    "- Find markers (areas with high vales)\n",
    "- Apply watershed segmentation\n",
    "- Remove small objects, likely to be noise\n",
    "\n",
    "Then, for each segmented image:\n",
    "- Add it in .uns['spatial'] as segmentation\n",
    "- Extract coordinates of segmented pixels and clean the adata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16ec217e-f612-4df7-a58d-66f94f553013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from adipo_finder import segmentation\n",
    "from adipo_finder import utils\n",
    "from joblib import Parallel, delayed\n",
    "# Wrapper function for normalization\n",
    "def normalize_function(mat):\n",
    "    mat=img_pre.normalize_channels_mat(mat, \n",
    "                                       method='arcsinh', \n",
    "                                       cofactor=None)\n",
    "    mat=img_pre.normalize_channels_mat(mat,method='quantile',quantile=.999)\n",
    "    return mat\n",
    "\n",
    "def parallel_normalization(img,n_jobs=-1):\n",
    "    # Process observations in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(normalize_function)(img[:,:,i]) for i in range(img.shape[2])\n",
    "    )\n",
    "    # sum normalized channels to increase signal\n",
    "    mat=np.sum(np.dstack(results),axis=2)\n",
    "    # Apply filter to reduce noise\n",
    "    mat=np.where(mat>20,mat,0)\n",
    "    return mat\n",
    "\n",
    "def sequential_normalization(img):\n",
    "    # Process observations sequentially\n",
    "    results=[]\n",
    "    for i in range(img.shape[2]):\n",
    "        results.append(normalize_function(img[:,:,i]))\n",
    "    # sum normalized channels to increase signal\n",
    "    mat=np.sum(np.dstack(results),axis=2)\n",
    "    # apply filter to reduce noise\n",
    "    mat=np.where(mat>20,mat,0)\n",
    "    return mat\n",
    "\n",
    "\n",
    "\n",
    "def run_segmentation(mat,library_id, sigma, window=1, min_size=100):\n",
    "    mat=utils.Preprocessing.apply_gaussian_filter(mat,sigma)\n",
    "    distance,markers=segmentation.Segmentation.find_local_maxima(mat)\n",
    "    segmented_image=segmentation.Segmentation.apply_watershed_segmentation(mat, markers, distance, window)\n",
    "    segmented_image=segmentation.Segmentation.filter_objects_by_size(segmented_image, min_size=min_size)\n",
    "    return {library_id: segmented_image}\n",
    "\n",
    "\n",
    "def parallel_segmentation(adatas,n_jobs=-1,sigma=.5):\n",
    "    # get all libraries\n",
    "    libraries = adatas.obs['library_id'].unique()\n",
    "    images={}\n",
    "    # First step, normalize in parallel al the channels for each image\n",
    "    for library_id in tqdm(libraries):\n",
    "        img=adatas.uns['spatial'][library_id]['images']['hires']\n",
    "        images[library_id]=parallel_normalization(img)\n",
    "    print('Normalization done\\nStarting parallel segmentation')\n",
    "    # Second step proceed with segmentation of each image\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(run_segmentation)(v,k,sigma) for k,v in images.items())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74bdc4ef-976e-4bd7-92ce-f00cf27be806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:40<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization done\n",
      "Starting parallel segmentation\n"
     ]
    }
   ],
   "source": [
    "results=parallel_segmentation(adatas,n_jobs=-1,sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac70bc07-3efc-40d6-a234-456eadc3ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={k: v for d in results for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a25055a-4c68-4f03-b899-3adb92b414e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_adata_by_library_and_coordinates(adatas, results):\n",
    "    # empty to populate with the filtering masks\n",
    "    filtered_mask=[]\n",
    "    for k,v in tqdm(results.items()):\n",
    "        # pre filter adata for the specific library_id speed up the process\n",
    "        adata=adatas[adatas.obs['library_id']==k]\n",
    "        # get x,y coordinates of nonzero pixels\n",
    "        y,x=v.nonzero()\n",
    "        # create list of x_y coordinates\n",
    "        filter_coords=list(map('_'.join,zip(x.astype(str),y.astype(str))))\n",
    "        # filtering mask for library_id\n",
    "        current_mask = adata.obs['coords'].isin(filter_coords)\n",
    "        # Add to the list of masks\n",
    "        filtered_mask.append(current_mask)\n",
    "        # add segmentation mask to adatas\n",
    "        adatas.uns['spatial'][k]['images']['segmentation']=v\n",
    "    # concat filtering masks\n",
    "    filtered_mask = pd.concat(filtered_mask)\n",
    "    # filter original\n",
    "    adata_filtered = adatas[filtered_mask].copy()\n",
    "    \n",
    "    return adata_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0d6c8001-64db-405c-aab4-a176bf8d43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas.obs['coords'] = adatas.obs['x'].astype(str) + '_' +adatas.obs['y'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3f6f28a8-985f-46e1-a688-7d0bcc882e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:29<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "adatas_clean=filter_adata_by_library_and_coordinates(adatas,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "213b287b-120c-45c7-8c81-cdbd4973f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3488099 × 39\n",
       "    obs: 'x', 'y', 'width_px', 'height_px', 'z', 'image', 'library_id', 'n_genes', 'coords'\n",
       "    uns: 'spatial'\n",
       "    layers: 'exprs'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adatas_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e99c1-c094-49cf-8daf-22db233f1a48",
   "metadata": {},
   "source": [
    "## Slides plot\n",
    "\n",
    "Plotting registered images, segmentation masks, kept pixels and original photos to verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f5d14779-63a3-46f5-aa07-62563315f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Sample: D0246\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def plot_slides(adatas,library_id, markers=['ICSK1','ICSK2']):\n",
    "    adata=adatas[adatas.obs['library_id']==library_id]\n",
    "    x_axis=2\n",
    "    y_axis=2\n",
    "    fig,axes=plt.subplots(2, 2, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    ## Plot original image with summed channels\n",
    "    img=np.sum(adata.uns['spatial'][library_id]['images']['hires'],axis=2)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Registered Image')\n",
    "    ## Plot segmentation image\n",
    "    axes[1].imshow(adata.uns['spatial'][library_id]['images']['segmentation'])\n",
    "    axes[1].set_title('Segmentation Image')\n",
    "    ## Plot points\n",
    "    axes[2].scatter(adata.obs['x'],\n",
    "                    adata.obs['y'],\n",
    "                    s=.1,\n",
    "                    c=sc.get.obs_df(adata,markers,\n",
    "                                    layer='exprs').sum(axis=1)\n",
    "                   )\n",
    "    axes[2].set_xlim(0,adata.obs['width_px'].unique())\n",
    "    axes[2].set_ylim(adata.obs['height_px'].unique(),0)\n",
    "    axes[2].set_aspect(adata.obs['height_px'].unique()/adata.obs['width_px'].unique())\n",
    "    axes[2].set_title('Scatterplot trasformed pixels')\n",
    "    ## Plot photo\n",
    "    png=plt.imread(f\"png_images/{adata.obs['image'].unique()[0]}_section{adata.obs['z'].unique()[0]}.png\")\n",
    "    axes[3].imshow(png)\n",
    "    axes[3].set_title('Photo')\n",
    "    fig.suptitle(library_id)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sample=images_ids[0]\n",
    "Markdown(f\"\"\"\n",
    "### Sample: {sample}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83fede-32b9-4549-bb8c-4d80b49187d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries=adatas[adatas.obs['image']==sample].obs['library_id'].unique()\n",
    "for library_id in libraries:\n",
    "    plot_slides(adatas_clean,library_id, markers=list(adatas.var_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93fe26-e9cd-422a-87f7-89971ceb275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=images_ids[1]\n",
    "Markdown(f\"\"\"\n",
    "### Sample: {sample}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d1896-a09d-4060-ba7f-59bc1a318267",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries=adatas[adatas.obs['image']==sample].obs['library_id'].unique()\n",
    "for library_id in libraries:\n",
    "    plot_slides(adatas_clean,library_id, markers=list(adatas.var_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27316e1-4b47-4cdf-b0af-24f535c510ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=images_ids[2]\n",
    "Markdown(f\"\"\"\n",
    "### Sample: {sample}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36badfaa-59d5-448a-8113-918a42cef394",
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries=adatas[adatas.obs['image']==sample].obs['library_id'].unique()\n",
    "for library_id in libraries:\n",
    "    plot_slides(adatas_clean,library_id, markers=list(adatas.var_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc7389-f126-4c54-a741-49a61147e976",
   "metadata": {},
   "source": [
    "## Save clean adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a63f3-a9cd-4563-b934-6159fe7e0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas_clean.write('./samples/adata_clean.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
